{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BiRNN_Sundar.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"_M0uL63bWzew","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import h5py\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Conv1D\n","from keras.layers import MaxPooling1D\n","from keras.layers import Flatten\n","from keras.layers import Dense, Activation, Embedding\n","from keras.layers import Dropout, TimeDistributed, Bidirectional\n","from keras.layers import LSTM, ConvLSTM2D, BatchNormalization\n","from keras import regularizers\n","from keras import losses\n","import tensorflow as tf\n","\n","import time"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2OkDUOD0W3bd","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/My Drive/Sundar_Notebooks\")\n","!ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ji-QfkFYWze3","colab_type":"code","colab":{}},"cell_type":"code","source":["X_test = np.load(\"X_test.npy\")\n","y_test = np.load(\"y_test.npy\")\n","person_train_valid = np.load(\"person_train_valid.npy\")\n","X_train_valid = np.load(\"X_train_valid.npy\")\n","y_train_valid = np.load(\"y_train_valid.npy\")\n","person_test = np.load(\"person_test.npy\")\n","\n","X_train_valid = np.swapaxes(X_train_valid,1,2)\n","X_test= np.swapaxes(X_test,1,2)\n","\n","print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n","print ('Test data shape: {}'.format(X_test.shape))\n","print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n","print ('Test target shape: {}'.format(y_test.shape))\n","print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n","print ('Person test shape: {}'.format(person_test.shape))\n","\n","y_train_valid -= 769\n","y_test -= 769\n","\n","#person_train_valid -= 769\n","#person_test -= 769\n","#y_train_valid = keras.utils.to_categorical(y_train_valid, 4)\n","#y_test = keras.utils.to_categorical(y_test, 4)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kJHXhY1tWze7","colab_type":"code","colab":{}},"cell_type":"code","source":["import pywt\n","import matplotlib.pyplot as plt\n","\n","feat_extract = False\n","num_signals = 22 ### 25 if using EOG, 22 otherwise\n","\n","if feat_extract:\n","    mother = 'db4'\n","    levels = 3\n","    mode = 'zero'\n","    feats_train_valid = pywt.wavedec(X_train_valid,mother,axis = 1, level = levels, mode = mode)\n","    feats_train_valid = np.concatenate(feats_train,axis = 1)\n","    feats_test = pywt.wavedec(X_test,mother,axis = 1, level = levels, mode = mode)\n","    feats_test = np.concatenate(feats_test,axis = 1)\n","else:\n","    feats_train_valid = X_train_valid\n","    feats_test = X_test\n","\n","feats_train_valid = feats_train_valid[:,:,0:num_signals]\n","feats_test = feats_test[:,:,0:num_signals]\n","\n","feat_scale = 'on' ####making features 0 mean and unit variance\n","\n","if feat_scale == 'on':\n","    temp = feats_train_valid - feats_train_valid.mean(axis=(0,1))\n","    temp = temp/feats_train_valid.std(axis=(0,1))\n","    feats_train_valid = temp\n","    temp = feats_test - feats_test.mean(axis=(0,1))\n","    temp = temp/feats_test.std(axis=(0,1))\n","    feats_test = temp\n","    \n","# f, ax = plt.subplots(5,5,figsize=(15,10))\n","\n","# for i in np.arange(22):\n","#     idx = i%5\n","#     idy = i//5\n","#     ax[idy,idx].plot(feats_train[45,:,i])\n","# plt.show()\n","\n","exp_mode = 'all' ## choices 'all','one_subject_train','one_subject_test'\n","val_split = 0.1\n","\n","if exp_mode == 'one_subject_train':\n","    subject = 0\n","    temp = feats_train_valid[person_train_valid[:,0]==subject]\n","    mask = np.random.permutation(temp.shape[0])\n","    mask_train = mask[0:int((1-val_split)*mask.shape[0])]\n","    mask_val = mask[int((1-val_split)*mask.shape[0]):]\n","    feats_train = temp[mask_train]\n","    feats_val = temp[mask_val]\n","    temp2 = y_train_valid[person_train_valid[:,0]==subject]\n","    y_train = temp2[mask_train]\n","    y_val = temp2[mask_val]\n","    \n","elif exp_mode == 'one_subject_test':\n","    subject = 0\n","    temp = feats_train_valid[person_train_valid[:,0]!=subject]\n","    mask = np.random.permutation(temp.shape[0])\n","    mask_train = mask[0:int((1-val_split)*mask.shape[0])]\n","    mask_val = mask[int((1-val_split)*mask.shape[0]):]\n","    feats_train = temp[mask_train]\n","    feats_val = temp[mask_val]\n","    temp2 = y_train_valid[person_train_valid[:,0]!=subject]\n","    y_train = temp2[mask_train]\n","    y_val = temp2[mask_val]\n","    \n","    feats_test = None\n","    y_test = None\n","    feats_test = feats_train_valid[person_train_valid[:,0]==subject]\n","    y_test = y_train_valid[person_train_valid[:,0]==subject]\n","\n","elif exp_mode == 'all':\n","    temp = feats_train_valid\n","    mask = np.random.permutation(temp.shape[0])\n","    mask_train = mask[0:int((1-val_split)*mask.shape[0])]\n","    mask_val = mask[int((1-val_split)*mask.shape[0]):]\n","    feats_train = temp[mask_train]\n","    feats_val = temp[mask_val]\n","    temp2 = y_train_valid\n","    y_train = temp2[mask_train]\n","    y_val = temp2[mask_val]\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"k30LyEk6Wze9","colab_type":"code","colab":{}},"cell_type":"code","source":["def birnn_model(features, labels, mode, params):\n","  \n","  num_hidden_layers = len(params['hidden_layers'])  \n","  \n","  input_layer = features[\"x\"]    \n","  \n","#   outputs = conv1 = tf.layers.conv1d(\n","#       inputs=input_layer,\n","#       filters=64,\n","#       kernel_size=[5],\n","#       padding=\"same\",\n","#       activation=tf.nn.relu)\n","  \n","  with tf.variable_scope(\"birnn_1\") as scope:\n","    cell1 = tf.nn.rnn_cell.LSTMCell(num_units = params['hidden_layers'][0])\n","    cell2 = tf.nn.rnn_cell.LSTMCell(num_units = params['hidden_layers'][1])\n","    outputs_bi, state = tf.nn.bidirectional_dynamic_rnn(cell_fw=cell1,cell_bw=cell2,\n","                                     inputs=input_layer,\n","                                     dtype=tf.float64)\n","\n","  outputs = tf.nn.relu(tf.concat(outputs_bi, 2))\n","  outputs = tf.layers.dropout(inputs=outputs, rate=0.5, training=(mode==tf.estimator.ModeKeys.TRAIN))\n","  outputs = tf.layers.batch_normalization(inputs=outputs)\n","  \n","#   with tf.variable_scope(\"birnn_2\") as scope:\n","#     cell3 = tf.nn.rnn_cell.LSTMCell(num_units = params['hidden_layers'][2])\n","#     cell4 = tf.nn.rnn_cell.LSTMCell(num_units = params['hidden_layers'][3])\n","#     outputs_bi, state = tf.nn.bidirectional_dynamic_rnn(cell_fw=cell3,cell_bw=cell4,\n","#                                    inputs=outputs,\n","#                                    dtype=tf.float64)\n","\n","#   outputs = tf.nn.relu(tf.concat(outputs_bi, 2))\n","#   outputs = tf.layers.dropout(inputs=outputs, rate=0.6, training=(mode==tf.estimator.ModeKeys.TRAIN))\n","#   outputs = tf.layers.batch_normalization(inputs=outputs)\n","\n","  \n","  #FLatten the output of LSTM layers\n","  outputs = tf.contrib.layers.flatten(outputs) \n","  \n","  outputs = tf.layers.dense(inputs=outputs, units=32)\n","  outputs = tf.nn.relu(outputs)\n","  \n","  outputs = tf.layers.dropout(inputs=outputs, rate=0.2, training=(mode==tf.estimator.ModeKeys.TRAIN))\n","  outputs = tf.layers.batch_normalization(inputs=outputs)\n","\n","  # FC Layer\n","  logits = tf.layers.dense(inputs=outputs, units=params['num_classes'])\n","\n","  predictions = {\n","      # Generate predictions (for PREDICT and EVAL mode)\n","      \"classes\": tf.argmax(input=logits, axis=1),\n","      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n","      # `logging_hook`.\n","      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n","  }\n","\n","  if mode == tf.estimator.ModeKeys.PREDICT:\n","    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n","\n","  # Calculate Loss (for both TRAIN and EVAL modes)\n","  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n","  tf.summary.scalar('loss', loss)\n","      \n","\n","  # Configure the Training Op (for TRAIN mode)\n","  if mode == tf.estimator.ModeKeys.TRAIN:\n","    optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])\n","    train_op = optimizer.minimize(\n","        loss=loss,\n","        global_step=tf.train.get_global_step())\n","    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n","\n","  # Add evaluation metrics (for EVAL mode)\n","  eval_metric_ops = {\n","      \"accuracy\": tf.metrics.accuracy(\n","          labels=labels, predictions=predictions[\"classes\"])}\n","  return tf.estimator.EstimatorSpec(\n","      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n","\n","  merged = tf.summary.merge_all()\n","  train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/train',\n","                                      sess.graph)\n","  test_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/test')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8lETzTrTssyL","colab_type":"code","colab":{}},"cell_type":"code","source":["import warnings \n","warnings.simplefilter('ignore')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2OizNLViWzfB","colab_type":"code","colab":{}},"cell_type":"code","source":["tf.reset_default_graph()\n","start = time.time()\n","eeg_classifier = tf.estimator.Estimator(model_fn=birnn_model, model_dir=\"model/\", \n","                                        params = {'hidden_layers' : [64,64,64,64], 'num_classes' : 4, 'learning_rate' : 0.001})\n","tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n","#logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n","train_input_fn = tf.estimator.inputs.numpy_input_fn(\n","    x={\"x\": feats_train},\n","    y=y_train,\n","    batch_size=50,\n","    num_epochs=None,\n","    shuffle=True)\n","\n","eeg_classifier.train(\n","    input_fn=train_input_fn,\n","    steps=100)\n","   #,hooks=[logging_hook])\n","\n","eval_train_fn = tf.estimator.inputs.numpy_input_fn(\n","    x={\"x\": feats_train},\n","    y=y_train,\n","    num_epochs=1,\n","    shuffle=False)\n","eval_train_results = eeg_classifier.evaluate(input_fn=eval_train_fn)\n","\n","eval_val_fn = tf.estimator.inputs.numpy_input_fn(\n","    x={\"x\": feats_val},\n","    y=y_val,\n","    num_epochs=1,\n","    shuffle=False)\n","eval_val_results = eeg_classifier.evaluate(input_fn=eval_val_fn)\n","\n","eval_test_fn = tf.estimator.inputs.numpy_input_fn(\n","    x={\"x\": feats_test},\n","    y=y_test,\n","    num_epochs=1,\n","    shuffle=False)\n","eval_test_results = eeg_classifier.evaluate(input_fn=eval_test_fn)\n","print('Train results are:',eval_train_results)\n","print('Validation results are:',eval_val_results)\n","print('Test results are:',eval_test_results)\n","end = time.time()\n","print('Time taken in min:',(end-start)//60)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"98KvIzh6WzfE","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","pred_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": feats_test},shuffle=False)\n","test_predi_info = eeg_classifier.predict(input_fn=pred_fn)\n","y_pred = []\n","for result in test_predi_info:\n","  y_pred.append(result['classes'])\n","y_pred = np.array(y_pred)\n","y_test_cm = np.load(\"y_test.npy\") -769\n","labels = [0,1,2,3]\n","cm = confusion_matrix(y_test_cm,y_pred, labels)\n","cm = cm/cm.sum(axis=0)\n","df_cm = pd.DataFrame(cm, index = [i for i in ['Left','Right','Legs','Tongue']],\n","                  columns = [i for i in ['Left','Right','Legs','Tongue']])\n","plt.figure(figsize = (10,7))\n","sn.heatmap(df_cm, annot=True)"],"execution_count":0,"outputs":[]}]}